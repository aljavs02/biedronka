---
title: "Supermarket"
subtitle: "Analiza czynników istotnie wpływających na satysfakcje klienta"
author: "A. Jaworska, G. Kuczyńska, M. Stalmach"
output:
  rmdformats::readthedown:
    highlight: kate
    toc_float: true
    toc_depth: 4
editor_options: 
  markdown: 
    wrap: 72
---

# Wstęp

## Opis problemu

Celem projektu jest eksploatacja historycznych danych dotyczących
sprzedaży w supermarketach oraz identyfikacja czynników mogących
istotnie wpływać na ocenę satysfakcji klientów dotyczącą ich ogólnego
doświadczenia zakupowego.

## Baza danych

Podstawą analizy był zbiór danych supermarket_new, zawierający dane
pochodzące z jednej z historycznych sprzedaży firm supermarketów, która
została zarejestrowana w 3 różnych oddziałach przez 3 miesiące.

```{r setup, message=FALSE, warning=FALSE, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)
options(scipen = 999, digits=6) 

# załadowanie potrzebnych bibliotek
library(dplyr) 
library(ggplot2)
library(VIM)
library(dlookr)
library(naniar)
library(validate)
library(VIM)
```

```{r}

# wczytanie danych 
library(readr) 
super <- read.csv("supermarket_new.csv")

```

```{r, echo=FALSE}

# wyświetlenie pierwszych 6 wierszy ze zbioru danych
knitr::kable(head(super))

```

# Zmienne

Zbiór danych supermarket_new zawiera następujące zmienne:

| Zmienna | Opis |
|------------------------|:-----------------------------------------------|
| **Invoice id** | Numer identyfikacyjny faktury sprzedaży (unikalna wartość) |
| **Branch** | Oddział supercentrum (3 oddziały oznaczone literami A, B, C). |
| **City** | Lokalizacja supercentrów |
| **Customer type** | Typ klienta (z kartą członkowską lub bez) |
| **Gender** | Płeć klienta |
| **Product line** | Ogólne grupy kategoryzacji przedmiotów |
| **Unit price** | Cena każdego produktu w \$ |
| **Quantity** | Liczba produktów zakupionych przez klienta |
| **Tax** | Opłata podatkowa w wysokości 5% dla klienta dokonującego zakupu |
| **Total** | Cena całkowita z podatkiem |
| **Date** | Data zakupu (rekord dostępny od 01.2019 do 03.2019) |
| **Time** | Czas zakupu (od 10:00 do 21:00) |
| **Payment** | Płatność wykorzystana przez klienta do zakupu (gotówka, karta kredytowa lub portfel elektroniczny) |
| **COGS** | Koszt sprzedanych towarów |
| **Gross margin percentage** | Procentowa marża brutto |
| **Gross income** | Dochód brutto |
| **Rating** | Ocena stratyfikacji klientów (w skali od 1 do 10) |

```{r}

# struktura danych
str(super)
```

Funkcja *str* pozwala na określenie struktury analizowanych danych.
Dzięki niej można określić typ analizowanych danych, całkowitą ich ilość
(1000) i ilość zmiennych (17)

```{r}
# statystyki podsumowujące
summary(super)

```

Dzięki funkcji *summary* można zauważyć, iż rekordy nie są kompletne i
niezbędne będzie przeprowadzenie ich czyszczenia co zostanie wykonane w
dalszej części projektu. Dodatkowo kod ten genruje wyniki minimalnych,
maksymalnych i średnich wartości zmiennych przyjmujących typ numeryczny
i liczb całkowitych oraz określa wartości mediany, 1. oraz 3. kwartla.

Dzięki powyższym wynikom można zauważyć poniższe zależności:

-   średnia ocena sklepu wynosi 7 punktów, natomiast żaden z klientów
    nie wystawił oceny niższej niż 4 
-   najdroższy zakup dokonany w tym sklepie w okresie od stycznia 2019
    do marca 2019 wynosiło 1042.7\$\
-   średnio klienci w tych oddziałach dokonywali zakupów na kwotę 323\$\
-   mediana niższa od średniej (253.8\$ \< 323\$) może wskazywać na
    prawoskośność rozkładu oraz na dużą liczbę wartości odstających 

Nieuwzględnione statystyki z powyższej tabeli zostaną szczegółowo
omówione w dalszej części analizy.

# 1. Data Cleansing & Data Wrangling
Wprowadzenie:
Celem tego skryptu jest kompleksowe oczyszczenie i przygotowanie danych z pliku "supermarket_new.csv". 
W szczególności skupimy się na identyfikacji i uzupełnieniu brakujących wartości w kluczowych kolumnach: City, Rating oraz gross.income. 
Dzięki zastosowaniu odpowiednich technik eksploracji, analizy oraz imputacji danych, końcowy zbiór będzie spójny, kompletny i gotowy do dalszych analiz.
```{r}

# 1. Wczytanie danych
biedra <- read.csv(file="supermarket_new.csv")  # Wczytanie danych z pliku CSV do ramki danych biedra.

# 2. Sprawdzenie brakujących danych
sum(is.na(biedra$City)==TRUE)  # Liczba braków w kolumnie City.
sum(is.na(biedra$Rating)==TRUE)  # Liczba braków w kolumnie Rating.
sum(is.na(biedra$gross.income)==TRUE)  # Liczba braków w kolumnie gross.income.
# Wynik: Braki w kolumnach - Rating (150), City (100), gross.income (150).

# Dalsza analiza braków w zbiorze
n_miss(biedra)  # Liczba wszystkich braków w zbiorze.
prop_miss(biedra)  # Procent braków w stosunku do całego zbioru danych.
miss_var_summary(biedra)  # Podsumowanie braków dla poszczególnych kolumn.
vis_miss(biedra)  # Wizualizacja braków w danych.
gg_miss_fct(biedra, fct = Gender)  # Analiza braków w kontekście kolumny Gender.
gg_miss_upset(biedra)  # Wizualizacja współwystępowania braków w różnych kolumnach.

# 3. Eksploracja danych
table(biedra$Gender)  # Tabela częstości dla kolumny Gender.
table(biedra$Rating)  # Tabela częstości dla kolumny Rating.
unique(biedra$Rating)  # Wyświetlenie unikalnych wartości w kolumnie Rating.
boxplot(biedra$Rating, outliers="red")  # Wykres pudełkowy dla Rating z zaznaczeniem wartości odstających.

# 4. Przekształcenia danych
biedra$Sex <- factor(biedra$Gender)  # Konwersja kolumny Gender na zmienną kategoryczną jako Sex.
table(biedra$Sex)  # Tabela częstości dla nowej kolumny Sex.

# 5. Imputacja brakujących danych w City (metoda sekwencyjna)
seqImpute <- function(x, last=max(x, na.rm=TRUE)) {  
  # Funkcja uzupełnia braki w danych, zastępując je kolejnymi dostępnymi wartościami.
  n <- length(x)  
  x <- c(x, last)  # Dodanie wartości zapasowej na końcu.
  i <- is.na(x)  # Identyfikacja braków w wektorze.
  while (any(i)) {  
    x[i] <- x[which(i)+1]  # Zastąpienie braków kolejnymi wartościami.
    i <- is.na(x)  # Aktualizacja indeksów braków.
  }
  x[1:n]  # Zwrot oryginalnej długości wektora.
}

o <- order(biedra$Branch)  # Sortowanie kolumny City według Branch.
biedra_City <- biedra$City[o]  # Posortowanie danych w kolumnie City.
biedra_City_hd <- seqImpute(biedra_City)  # Uzupełnienie braków w City za pomocą funkcji seqImpute.
table(biedra_City_hd)  # Podsumowanie nowej kolumny City.
table(biedra$City)  # Podsumowanie oryginalnej kolumny City.

# 6. Imputacja braków w pozostałych kolumnach metodą KNN
biedra_knn <- kNN(biedra)  # Imputacja braków metodą K-Nearest Neighbors.
biedra_gross_income <- biedra_knn$gross.income  # Przypisanie wartości imputowanych dla gross.income.
biedra_Rating <- biedra_knn$Rating  # Przypisanie wartości imputowanych dla Rating.
biedra$Rating <- biedra_Rating  # Zastąpienie oryginalnej kolumny Rating imputowaną wersją.
biedra$gross.income <- biedra_gross_income  # Zastąpienie oryginalnej kolumny gross.income imputowaną wersją.
biedra$City <- biedra_City_hd  # Przypisanie oczyszczonej kolumny City do zbioru danych.

```
# Zakończenie:
Proces oczyszczania danych został zakończony. Zastosowane metody pozwoliły na uzupełnienie brakujących wartości w spójny i logiczny sposób. 
Zbiór danych jest teraz kompletny i gotowy do dalszych analiz, co pozwala na precyzyjne wyciąganie wniosków i tworzenie modeli analitycznych.
